{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will learn\n",
        "\n",
        "\n",
        "1.   Simple Extract function\n",
        "2.   Simple Transform Function\n",
        "3.   Simple Load Function\n",
        "4.   Simple Logging Function\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XVHew8P_9jdY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dDCabW3sVtIc"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we have to write function for 3 different file format .csv,.xml,.json\n",
        "def extract_from_csv(file_to_process):\n",
        "    dataframe = pd.read_csv(file_to_process)\n",
        "    return dataframe\n",
        "#for json\n",
        "def extract_from_json(file_to_process):\n",
        "    dataframe = pd.read_json(file_to_process, lines=True)\n",
        "    return dataframe\n",
        "#for xml\n",
        "def extract_from_xml(file_to_process):\n",
        "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
        "    tree = ET.parse(file_to_process)\n",
        "    root = tree.getroot()\n",
        "    for person in root:\n",
        "        name = person.find(\"name\").text\n",
        "        height = float(person.find(\"height\").text)\n",
        "        weight = float(person.find(\"weight\").text)\n",
        "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "zzuv_WGk1bLs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are using extract function to identify a function on basis of filetype on data file\n",
        "#here for extract function and #glob library to identify all filetype\n",
        "def extract():\n",
        "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
        "\n",
        "    # process all csv files\n",
        "    for csvfile in glob.glob(\"*.csv\"):\n",
        "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
        "\n",
        "    # process all json files\n",
        "    for jsonfile in glob.glob(\"*.json\"):\n",
        "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True)\n",
        "\n",
        "    # process all xml files\n",
        "    for xmlfile in glob.glob(\"*.xml\"):\n",
        "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True)\n",
        "\n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "W3J-AbcE6xLO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRANSFORMATION\n",
        "#here we are using transform function which will receive extracted dataframe as input\n",
        "def transform(data):\n",
        "    # convert inches into meters and round off to two decimals\n",
        "    data['height']=round(data.height * 0.0254,2)\n",
        "# convert pounds to kilograms and roundoff to two decimals\n",
        "# 1 pound is 0.45359237 kilograms\n",
        "    data['weight']=round(data.weight*0.45359237,2)\n",
        "    return data"
      ],
      "metadata": {
        "id": "ab8qDDcE8ikj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOADING AND LOGGING\n",
        " #to load the data\n",
        "#we need a function load_data() which accepts the transformes data as a dataframe and the target_file path which you need use the to_csv() attribute of the dataframe in the functions as follows\n",
        "def load_data(target_file,transformed_data):\n",
        "    transformed_data.to_csv(target_file)\n",
        "#Here we are implementing the logging operation to record the progress of the different operations along with its timestamp in #log_file\n",
        "#log_progress() which accepts the log message as the arguement.function which capture the current data and tie usisng the datetime functio from the datetime library.\n",
        "\n",
        "def log_progress(message):\n",
        "    timestamp_format='%y-%h-%d-%H:%M:%S' #year-monthname-Day-Hour-Minute-Second\n",
        "    now=datetime.now()#get current timestamp\n",
        "    timestamp=now.strftime(timestamp_format)\n",
        "    with open(log_file,\"a\") as f:\n",
        "        f.write(timestamp +','+message +'\\n')"
      ],
      "metadata": {
        "id": "4lGqYE4o8jdF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#log the initiallization of the ETL process\n",
        "log_progress(\"ETL job started\")\n",
        "\n",
        "#log the beginning of the extraction process\n",
        "log_progress(\"extract phase started\")\n",
        "extracted_data=extract()\n",
        "# Log the beginning of the Transformation process\n",
        "log_progress(\"Transform phase started\")\n",
        "transform_data=transform(extracted_data)\n",
        "print(\"transformed data\")\n",
        "print(transform_data)\n",
        "\n",
        "# Log the completion of the Transformation process\n",
        "log_progress(\"Transform phase ended \")\n",
        "\n",
        "# Log the beginning of the Loading process\n",
        "log_progress(\"Load phase Started\")\n",
        "load_data(target_file,transform_data)\n",
        "\n",
        "# Log the completion of the Loading process\n",
        "log_progress(\"Load phase Ended\")\n",
        "\n",
        "# Log the completion of the ETL process\n",
        "log_progress(\"ETL Job Ended\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6r52pvW8r7G",
        "outputId": "38fbb60d-cb32-4d63-bf30-9bbc4122d915"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformed data\n",
            "Empty DataFrame\n",
            "Columns: [name, height, weight, Unnamed: 0.1, Unnamed: 0]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-hBV9258ypE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}